{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "47d6116d-48d0-4753-8b1e-da829a7c554c",
   "metadata": {},
   "source": [
    "## Import library\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87a87a6c-6184-4fc6-bef2-14eaa849c2ee",
   "metadata": {},
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "130415c2-8547-413c-8ba9-552c8c8e2fb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "R=[]\n",
    "S=[]\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32f5d9a0-62bd-4723-9f73-8c32adb311e8",
   "metadata": {},
   "source": [
    "## Get the images from the folder\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "eb85ab78-1bb3-4cd6-8531-48d41e1d486a",
   "metadata": {},
   "outputs": [],
   "source": [
    "img=os.listdir(\"d:/rajeev_img\")\n",
    "for i in img:\n",
    "    imgs=cv2.imread(f\"d:/rajeev_img/{i}\")\n",
    "    img2=cv2.resize(imgs,(100,100))\n",
    "    \n",
    "    gray_img=cv2.cvtColor(img2,cv2.COLOR_BGR2GRAY)                \n",
    "                    \n",
    "    gray_img=gray_img/255\n",
    "    R.append(gray_img.flatten())\n",
    "    S.append(\"Rajeev\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55ac2c14-a0fe-4f4a-9445-0e85f12397a3",
   "metadata": {},
   "source": [
    "## Get the images from the folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ceabd0b4-1a1f-45b8-8331-df83c6ade63d",
   "metadata": {},
   "outputs": [],
   "source": [
    "img=os.listdir(\"d:/meenu\")\n",
    "for i in img:\n",
    "    imgs=cv2.imread(f\"d:/meenu/{i}\")\n",
    "    img2=cv2.resize(imgs,(100,100))\n",
    "    gray_img=cv2.cvtColor(img2,cv2.COLOR_BGR2GRAY)                \n",
    "                    \n",
    "    gray_img=gray_img/255\n",
    "    R.append(gray_img.flatten())\n",
    "    S.append(\"Meenu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f774686b-8b90-431c-b815-948bfb7e0183",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "## Sample image and extracting feature\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7cdc6516-bb5b-4afc-b08d-74b17c923ea0",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.58823529, 0.58823529, 0.58823529, ..., 0.36862745, 0.36862745,\n",
       "       0.47843137])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imgs=cv2.imread(f\"e:/female/344.png\")\n",
    "img2=cv2.resize(imgs,(100,100))\n",
    "    \n",
    "gray_img=cv2.cvtColor(img2,cv2.COLOR_BGR2GRAY)  \n",
    "gray_img=gray_img/255 # Features extracting from the images and convert \n",
    "gray_img.flatten()\n",
    "                    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe1285be-11ab-47bd-b51b-9ab77befbe6b",
   "metadata": {},
   "source": [
    "## Model training\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "be29a98a-911d-42db-b6f6-f73ca8e92dfc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression()"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "model=LogisticRegression()\n",
    "model.fit(R,S)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ece1f00-6818-4fb5-8e54-363928042db9",
   "metadata": {},
   "source": [
    "## Read the images from webcam at run time\n",
    "|\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d7288cf7-b46e-4abf-b845-faa3d2e28a1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "vdo=cv2.VideoCapture(0)\n",
    "c=1\n",
    "z=[]\n",
    "face_model=cv2.CascadeClassifier(\"E:/image_detection_haarcascadefile/haarcascade_frontalface_default.xml\")\n",
    "while True:\n",
    "    flag,img=vdo.read()\n",
    "    if flag==False:\n",
    "        break\n",
    "    gray_img=cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    img_face=face_model.detectMultiScale(gray_img,minNeighbors=8,scaleFactor=1.3)\n",
    "    for x,y,w,h in img_face:\n",
    "        cv2.rectangle(img,(x,y),(x+w,y+h),(0,255,0),2)\n",
    "        face=img[y:y+w,x:x+h]\n",
    "        img2=cv2.resize(face,(100,100))\n",
    "    \n",
    "        gray_img=cv2.cvtColor(img2,cv2.COLOR_BGR2GRAY)  \n",
    "        gray_img=gray_img/255\n",
    "        gray_img.flatten()\n",
    "        pred=model.predict([gray_img.flatten()])\n",
    "        prob=model.predict_proba([gray_img.flatten()])\n",
    "        cv2.putText(img,pred[0],(x,y),cv2.FONT_HERSHEY_PLAIN,2,(255,255,2),2)\n",
    "        cv2.putText(img,\"%.2f\"%(np.max(prob[0])),(y,y+17),cv2.FONT_HERSHEY_PLAIN,2,(255,255,2),2)\n",
    "        #cv2.putText(img,\"%.2f\"%(np.max(prob[0])),(y,y+22),cv2.FONT_HERSHEY_PLAIN,2,(255,255,2),2)\n",
    "        \n",
    "        z.append(c)\n",
    "        #print(len(z))\n",
    "        \n",
    "        \n",
    "    c+=1\n",
    "    cv2.imshow(\"color img\",img)\n",
    "    #print(len(z))\n",
    "    key=cv2.waitKey(25)\n",
    "    if key==ord('q'):\n",
    "        break\n",
    "#print(len(z))\n",
    "cv2.destroyAllWindows()\n",
    "vdo.release()\n",
    "         \n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ae3e94d-b4bd-4b6d-8f2b-9a32cbf252e5",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "da28ca01-3133-4530-892b-6b65b9d4d446",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e29768b6-6e46-47dd-a360-6a987eac6882",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05476cef-2a16-4f74-9cd7-fb7bfea95094",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
